{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c2e0764-97bb-4eb9-83e7-e4a25116edf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "034cbcac-4c17-4937-a3b6-2aa6191ebeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4afabe-9601-4f60-9c24-db9689b0ee57",
   "metadata": {},
   "source": [
    "### Creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a418041-f4c4-4ff9-bfb2-2fcd9cb5657c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb4502da-8fef-49ff-9444-6280dccbf72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b8587b-58aa-4b43-968f-fa6b40ee7da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5faddd0b-1636-4065-89df-ccd0e8cec82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f035401-4e94-4672-9b2a-437cb461d8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1209eb8f-1ca6-468a-b2ae-07989003417e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "107038ef-6e4d-4a20-b3ef-daf1e57d9717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf51e2d0-cfe0-444d-91ce-c7d16a6561e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor([[7]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44b524c2-fe56-4efa-8767-4935bb44da48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34dd44a3-4a6a-4c2e-a35d-69bc422a2520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c16d6ac8-9ceb-4a6f-a3c6-f374a83071c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0ad1851-c7a3-4154-89d0-293117fc77fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([7, 8])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7162f5fe-68db-4b6d-bbf1-465115e410a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b6b56e5-89a7-4b56-b754-58f4adde8d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dfe22f1-bfc8-4f3a-994c-17f0433b2f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only works for scalars and one element tensor\n",
    "# vector.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2933b41-a6e4-4684-b578-2d1a991f1d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3195d4c4-8eaa-4ee1-ab63-304bab891ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74b99845-37f8-4edb-92c8-9c5ea09a93d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d9322e7-5f7c-460d-9141-fa02259b1b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor([[1, 2], \n",
    "                       [3, 4]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4205bbf5-5fea-42bf-a7e4-b4ced556bfaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8942b47f-9578-4ff1-9bb5-c6a56ece058c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a50631a-bdf7-4e4f-923a-b9106c6b0d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[[1, 2, 3], \n",
    "                       [4, 5, 6], \n",
    "                       [7, 8, 9]]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2645965-ebdb-4be0-b63d-a168d1a24737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7294bce5-3a59-48e9-9e04-b364f250b810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c253ac7-c842-4ba2-b722-219870d0fee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 7] int64\n",
      "tensor([7, 7]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "np_vector = np.array([7, 7])\n",
    "pt_vector = torch.tensor(np_vector)\n",
    "\n",
    "print(np_vector, np_vector.dtype)\n",
    "print(pt_vector, pt_vector.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2afcc0a-b463-46be-abbc-7dc20480d3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 7] int64\n",
      "tensor([7, 7]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "np_vector[0] = 8\n",
    "\n",
    "print(np_vector, np_vector.dtype)\n",
    "print(pt_vector, pt_vector.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c200eb2-301c-4cb4-925a-c5fa17488d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 7] int64\n",
      "tensor([7, 7]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "np_vector = np.array([7, 7])\n",
    "pt_vector = torch.as_tensor(np_vector)\n",
    "\n",
    "print(np_vector, np_vector.dtype)\n",
    "print(pt_vector, pt_vector.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30dbea4b-c6b3-474b-9be3-bcd4cf61d04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 7] int64\n",
      "tensor([8, 7]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "np_vector[0] = 8\n",
    "\n",
    "print(np_vector, np_vector.dtype)\n",
    "print(pt_vector, pt_vector.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d62b3a7-f0c2-4d1a-8d8f-e072ec568ec7",
   "metadata": {},
   "source": [
    "### Random tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71dc02f6-ab45-46b9-a938-b052415a2559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6136, 0.4396, 0.3336, 0.5655],\n",
       "         [0.7028, 0.7243, 0.8637, 0.4852],\n",
       "         [0.2603, 0.5805, 0.0118, 0.7381]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4dc6b48-c2d9-4c48-aaeb-39bec7bb5418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 224, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_tensor = torch.rand(224, 224, 3)\n",
    "random_image_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce45489-cbaf-427b-9970-5eb1da2b8bdb",
   "metadata": {},
   "source": [
    "### Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "970048cf-31c9-4078-a75b-ce0d349956eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(3, 4)\n",
    "zeros, zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67bfee34-4d3c-4a7b-b098-d978564ff9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(3, 4)\n",
    "ones, ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb80661b-154e-4f86-8e48-e85db348c3f0",
   "metadata": {},
   "source": [
    "### Creating a range and tensors like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b70771cc-3cd1-49ea-8c48-03d9a8064096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zk/thhxnpgj5xd1lq4z__k6cswr0000gp/T/ipykernel_40961/726760739.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  zero_to_ten_deprecated = torch.range(0, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_ten_deprecated = torch.range(0, 10)\n",
    "zero_to_ten_deprecated, zero_to_ten_deprecated.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c74ec20-8272-4ee5-a742-47ef1eaf28b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a4ef199-c7b4-4370-b378-dd860eecbee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), torch.int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
    "zero_to_ten, zero_to_ten.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "699d9c9c-3e5d-4ba5-8cb6-a213db2a8fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), torch.int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_zeros = torch.zeros_like(zero_to_ten)\n",
    "ten_zeros, ten_zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6746fc3-3ed1-4841-a325-381726bbf31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), torch.int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_ones = torch.ones_like(zero_to_ten)\n",
    "ten_ones, ten_ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2fc6f2dd-50df-42fc-87c5-a1281ceca7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.9669, 0.4676, 0.4196, 0.2880, 0.1174, 0.9107, 0.3700, 0.0232, 0.4558,\n",
       "         0.4991]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_rand_nums = torch.rand_like(zero_to_ten.type(torch.float32))\n",
    "ten_rand_nums, ten_rand_nums.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00271697-8641-4c5d-bfd3-124af5608606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_ten_float = torch.arange(start=0, end=10, step=1, dtype=torch.float32)\n",
    "zero_to_ten_float, zero_to_ten_float.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f14baa6e-992b-4643-b8b1-ae9c8f0c394f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), torch.float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_zeros = torch.zeros_like(zero_to_ten_float)\n",
    "ten_zeros, ten_zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd1b80f8-312b-494b-8446-2b5b90322cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), torch.float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_ones = torch.ones_like(zero_to_ten_float)\n",
    "ten_ones, ten_ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572488bd-522e-4681-b092-4f12be48db10",
   "metadata": {},
   "source": [
    "### Tensor datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "703badee-b9d7-46a2-84c8-87c4eaa4fe1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], \n",
    "                               dtype=None,  # defaults to None, which is torch.float32 or whatever datatype is passed \n",
    "                               device=None,  # defaults to None, which uses the cpu\n",
    "                               requires_grad=False)  # if true, operations performed on the tensor are recorded\n",
    "float_32_tensor.ndim, float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d52edb6-e00f-4891-acb4-7d3be0a30825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79e5452-6c14-4b4d-9463-e7fe1a5f38b7",
   "metadata": {},
   "source": [
    "### Getting information from tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "63e1e496-d205-4c3f-bddb-00c59e703a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1048, 0.8328, 0.9024, 0.7007],\n",
      "        [0.2550, 0.0313, 0.9600, 0.4988],\n",
      "        [0.2400, 0.3003, 0.9072, 0.5137]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "some_tensor = torch.rand(3, 4)\n",
    "\n",
    "print(some_tensor)\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9852bf9-b108-46e6-9ceb-2a1a9debfded",
   "metadata": {},
   "source": [
    "### Manipulating tensors (tensor operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50c1beda-c0d9-4758-b89f-0820cb4edabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10583bac-c40c-4e0c-95e3-14f27776f46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "554e95da-2098-4ad4-89b3-5adb9f13d7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28ad5e0a-c433-4a14-8526-ccf83e132739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor - 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e076f41-ce26-4dac-b12d-cb30b0244fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor + 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d9e9323-aee5-402f-9de3-dde44c6fd582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "28e9874e-86f9-44a4-aa6e-4c0d68593094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b591278d-5766-4bf4-93ba-3e99124296d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sub(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d7f32edc-a745-4399-b6cf-dd2a1e5101b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d3cac293-0f4f-4658-b386-157e874545ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.div(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9be219b7-cc01-4200-9aca-4b3dec7dfad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504a755d-12b8-4e76-8a0c-e3af57d35d23",
   "metadata": {},
   "source": [
    "### Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0293493e-a61e-44ff-8d3b-685a50f6fd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3], dtype=torch.int32)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4e242368-20ce-444d-b0f3-811181d0be01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f100d561-51ab-4620-828a-95e877dfb6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14, dtype=torch.int32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "67ea70e4-bcd6-4371-a101-1c54bf8c9d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14, dtype=torch.int32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bf7d48a6-508c-4c23-a3d3-db3447df383b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.6 μs ± 16.9 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += (tensor[i] * tensor[i])\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "56049059-1a10-4ca0-8426-b4685dfc1464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "732 ns ± 1.5 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5592e8f3-f061-489f-8c5f-989ebc16e1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='mps:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor.to(\"mps\")\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6477b7cd-4d9b-4257-9d0c-f5b0506b7609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 μs ± 24.9 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fc677a6b-f7a5-434e-84c3-f9ef4433f47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 10000]), torch.float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_tensor = torch.rand(10_000, 10_000)\n",
    "big_tensor.shape, big_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "af85dfa0-cd03-48e8-9181-bb24e76afe5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12 s ± 8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "big_tensor @ big_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8ef0dd29-e8ce-4403-b619-a9686e9f07d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_tensor = big_tensor.to(\"mps\")\n",
    "big_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dea35104-5870-46d1-b855-8de9e2bfc878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 μs ± 29.7 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "\n",
    "big_tensor @ big_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d64dad33-bd86-4091-bbb5-94d11a7ec010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a = torch.tensor([[1., 2.], \n",
    "                         [3., 4.], \n",
    "                         [5., 6.]])\n",
    "tensor_b = torch.tensor([[7., 10.], \n",
    "                         [8., 11.], \n",
    "                         [9., 12.]])\n",
    "tensor_a.shape, tensor_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "50e04fe4-8c96-4e4d-8e9b-f353db71ec61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tensor_a @ tensor_b\n",
    "except RuntimeError as e:\n",
    "    print(f\"Failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "48428308-7daf-4bf1-bec4-8becdc0c739d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_a)\n",
    "print(torch.transpose(tensor_b, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "39c9b5b0-81f3-44e6-90ee-587ce08ada8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_a)\n",
    "print(tensor_b.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "26c9ac40-9ab0-4dd4-a837-e8aaf942592e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.,  30.,  33.],\n",
       "        [ 61.,  68.,  75.],\n",
       "        [ 95., 106., 117.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a @ tensor_b.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b7309246-d0ae-4cae-a065-b3edd6320cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.,  30.,  33.],\n",
       "        [ 61.,  68.,  75.],\n",
       "        [ 95., 106., 117.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor_a, tensor_b.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3190bad2-8272-4362-9d5f-fe1c995cf723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.,  30.,  33.],\n",
       "        [ 61.,  68.,  75.],\n",
       "        [ 95., 106., 117.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor_a, tensor_b.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9cdbe911-b7b2-4b55-9d6a-0407c7181555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
      "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
      "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "linear = torch.nn.Linear(in_features=2, out_features=6)\n",
    "\n",
    "x = tensor_a\n",
    "output = linear(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b79f667-2473-43ab-b340-75b65eba7056",
   "metadata": {},
   "source": [
    "### Finding min, max, mean, sum, etc (aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1258fd31-2e06-4c15-a8eb-654f16ffd164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(start=1, end=100, step=10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2a6ed925-51df-4f8c-b455-d06c3cc088f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 1\n",
      "Max: 91\n",
      "Mean: 46.0\n",
      "Sum: 460\n"
     ]
    }
   ],
   "source": [
    "print(f\"Min: {x.min()}\")\n",
    "print(f\"Max: {x.max()}\")\n",
    "print(f\"Mean: {x.type(torch.float32).mean()}\")\n",
    "print(f\"Sum: {x.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8ba0d0c2-a6f3-4839-b083-5474f6d747b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 1\n",
      "Max: 91\n",
      "Mean: 46.0\n",
      "Sum: 460\n"
     ]
    }
   ],
   "source": [
    "print(f\"Min: {torch.min(x)}\")\n",
    "print(f\"Max: {torch.max(x)}\")\n",
    "print(f\"Mean: {torch.mean(x.type(torch.float))}\")\n",
    "print(f\"Sum: {torch.sum(x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "07d271db-11be-48f2-9c1f-35e472bc803d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Index where max value occurs: 8\n",
      "Index where min value occurs: 0\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(10, 100, 10)\n",
    "\n",
    "print(f\"Tensor: {tensor}\")\n",
    "print(f\"Index where max value occurs: {torch.argmax(tensor)}\")\n",
    "print(f\"Index where min value occurs: {torch.argmin(tensor)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce4c829-7e30-4fec-9fde-4b6a6dcd0da2",
   "metadata": {},
   "source": [
    "### Changing datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "35ab1fd9-0e57-48ac-b8fd-d35f9d8bcd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.arange(10., 100., 10.0)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4535a3db-4a6b-4497-9902-6395f08ee653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float16 = tensor.type(torch.float16)\n",
    "tensor_float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "63adfa26-616c-4248-9a5a-9058664ecf7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_int8 = tensor.type(torch.int8)\n",
    "tensor_int8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcb2e7f-6f60-449f-9d08-1147e0ddf920",
   "metadata": {},
   "source": [
    "### Reshaping, stacking, squeezing, unsqueezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "24867ded-d843-486c-b9b2-c5ed7a0462d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 8.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "efe312b9-8ca1-4c58-9ed3-c3e9f5065f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped_1 = x.reshape(1, 7)\n",
    "x_reshaped_1, x_reshaped_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "065f1c39-2e43-494d-a4ec-a60b566c5cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.]]),\n",
       " torch.Size([7, 1]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped_2 = x.reshape(7, 1)\n",
    "x_reshaped_2, x_reshaped_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "60bf8b19-3ac3-4d2e-ba08-2d43158bb9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.view(1, 7)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ee07add2-8b31-42a3-8c2b-8b2061ce2782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a7379c8f-ad6c-47ff-af82-e6b5f2cd6815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7.]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "da6b23f5-d902-4f9b-bf11-b344f26b7b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "916f738e-9b51-4d89-b79c-135ec4c4052f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.],\n",
       "         [ 9., 10., 11., 12.]]),\n",
       " torch.Size([3, 4]))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 13.).reshape(3, 4)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7f95bd61-f85b-4fd0-9452-57c258017ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e72ad6aa-8769-4efe-b309-2d17648687d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  5.,  9.],\n",
       "         [ 2.,  6., 10.],\n",
       "         [ 3.,  7., 11.],\n",
       "         [ 4.,  8., 12.]]),\n",
       " torch.Size([4, 3]))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = x.transpose(0, 1)\n",
    "x_t, x_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1000155a-68d6-4ad3-9b90-d5fbabbc3bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "769c92e3-eaca-42ec-b221-fc8b851251c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  5.],\n",
      "        [ 9.,  2.],\n",
      "        [ 6., 10.],\n",
      "        [ 3.,  7.],\n",
      "        [11.,  4.],\n",
      "        [ 8., 12.]])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    x_reshape = x_t.reshape(6, 2)\n",
    "    print(x_reshape)\n",
    "except RuntimeError as e:\n",
    "    print(f\"Failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "efdac8c0-4648-4cd6-ab09-87127add4cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    x_view = x_t.view(6, 2)\n",
    "    print(x_view)\n",
    "except RuntimeError as e:\n",
    "    print(f\"Failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d286d8c9-1801-437e-968f-a3535ba00c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7.])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 8.)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8c86a3d5-c204-4f45-a395-b1bc4cb04841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5., 5.],\n",
       "        [6., 6., 6., 6., 6.],\n",
       "        [7., 7., 7., 7., 7.]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([x, x, x, x, x], dim=1)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "70ac8654-dc86-4c10-8d71-02c52617436d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[1]])\n",
      "Previous shape: torch.Size([1, 1])\n",
      "\n",
      "New Tensor: 1\n",
      "\n",
      "New shape: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1]])\n",
    "print(f\"Previous tensor: {x}\")\n",
    "print(f\"Previous shape: {x.shape}\")\n",
    "\n",
    "x_squeezed = x.squeeze()\n",
    "print(f\"\\nNew Tensor: {x_squeezed}\")\n",
    "print(f\"\\nNew shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0f1d5ecb-eb69-42e0-a798-d87ae94929f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "Previous shape: torch.Size([3, 1])\n",
      "\n",
      "New Tensor: tensor([1, 2, 3])\n",
      "\n",
      "New shape: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1], [2], [3]])\n",
    "print(f\"Previous tensor: {x}\")\n",
    "print(f\"Previous shape: {x.shape}\")\n",
    "\n",
    "x_squeezed = x.squeeze()\n",
    "print(f\"\\nNew Tensor: {x_squeezed}\")\n",
    "print(f\"\\nNew shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "503186ad-afb3-46e5-bda6-488a2ea415bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[[1],\n",
      "         [2],\n",
      "         [3]]])\n",
      "Previous shape: torch.Size([1, 3, 1])\n",
      "\n",
      "New Tensor: tensor([1, 2, 3])\n",
      "\n",
      "New shape: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[[1], [2], [3]]])\n",
    "print(f\"Previous tensor: {x}\")\n",
    "print(f\"Previous shape: {x.shape}\")\n",
    "\n",
    "x_squeezed = x.squeeze()\n",
    "print(f\"\\nNew Tensor: {x_squeezed}\")\n",
    "print(f\"\\nNew shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1a66f655-1269-4e7e-854c-d1f21fe99621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([1, 2, 3])\n",
      "Previous shape: torch.Size([3])\n",
      "\n",
      "New tensor: tensor([[[1],\n",
      "         [2],\n",
      "         [3]]])\n",
      "New shape: torch.Size([1, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "x_unsqueezed = x_unsqueezed.unsqueeze(dim=2)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "69c5714e-c7be-43ae-ae1f-da9070be0add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6]]]),\n",
       " torch.Size([1, 2, 3]))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[[1, 2, 3], \n",
    "                        [4, 5, 6]]])\n",
    "tensor, tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "093b995d-e031-467b-bd6e-d6810ac919fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5d55d1a5-833b-4237-9fa4-fedf02317cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2]],\n",
       " \n",
       "         [[3, 4]],\n",
       " \n",
       "         [[5, 6]]]),\n",
       " torch.Size([3, 1, 2]))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_tensor = tensor.reshape(3, 1, 2)\n",
    "reshaped_tensor, reshaped_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b82161ec-c2e4-4fc5-8c65-4193a24c5a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_tensor.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a74ffbda-bc77-4567-b974-b1dd29206bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 1)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_tensor.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6c9a0f32-e6ee-4acd-95e3-f437c2558b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 4]],\n",
       " \n",
       "         [[2, 5]],\n",
       " \n",
       "         [[3, 6]]]),\n",
       " torch.Size([3, 1, 2]))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permuted_tensor = tensor.permute(2, 0, 1)\n",
    "permuted_tensor, permuted_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4057b405-127d-4039-898b-efc910f33c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permuted_tensor.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ab295f66-f9c0-47b8-a110-6a6eac01b0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6, 3)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permuted_tensor.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c802cb-ff89-430b-9f04-6f2107c42eeb",
   "metadata": {},
   "source": [
    "The concept of the conguity has to due to the row-major order. \n",
    "\n",
    "#### Understanding Row-Major Order\n",
    "\n",
    "In row-major order (used by PyTorch and NumPy), the elements of a multi-dimensional array are stored in memory such that the last dimension changes the fastest, followed by the second-last dimension, and so on. This means that for a tensor with shape (D0, D1, D2):\n",
    "\n",
    "* Elements along D2 (the last dimension) are stored next to each other in memory.\n",
    "* Moving along D1 involves skipping all elements in D2.\n",
    "* Moving along D0 involves skipping all elements in both D1 and D2.\n",
    "\n",
    "For a tensor to be contiguous in memory, it needs to follow this pattern. The stride for the last dimension must be 1, and for the preceding dimensions, it should be the product of all subsequent dimensions.\n",
    "\n",
    "#### Impact of permute on Contiguity\n",
    "\n",
    "When you apply the permute operation, you are changing the order of dimensions without changing the underlying data layout. This affects how the data is accessed according to the strides but does not re-align the data in memory to follow the row-major order for the new shape.\n",
    "\n",
    "Example Recap\n",
    "\n",
    "Original tensor (before permute):\n",
    "\n",
    "* Shape: (1, 2, 3)\n",
    "* Strides: (6, 3, 1)\n",
    "\n",
    "This means:\n",
    "* To move between elements in the last dimension (3), move 1 step in memory.\n",
    "* To move between elements in the middle dimension (2), move 3 steps.\n",
    "* To move between elements in the first dimension (1), move 6 steps.\n",
    "\n",
    "After permute(2, 0, 1):\n",
    "\n",
    "* New shape: (3, 1, 2)\n",
    "* New strides: (1, 6, 3)\n",
    "\n",
    "The new strides indicate:\n",
    "* To move between elements in the new last dimension (2), move 3 steps in memory.\n",
    "* To move between elements in the new middle dimension (1), move 6 steps.\n",
    "* To move between elements in the new first dimension (3), move 1 step.\n",
    "\n",
    "#### Why It Becomes Non-Contiguous\n",
    "\n",
    "The new strides after permute do not match the typical row-major layout (where the last dimension should have a stride of 1). Instead:\n",
    "* The last dimension (2 after permute) has a stride of 3, which breaks the row-major order assumption.\n",
    "\n",
    "Because of this mismatch between the expected stride pattern for a contiguous layout and the actual strides, the tensor is marked as non-contiguous.\n",
    "\n",
    "#### Summary\n",
    "\n",
    "* Row-major order is central to why the tensor becomes non-contiguous after permute.\n",
    "* Contiguity requires that the last dimension has a stride of 1, and preceding dimensions have strides that reflect the product of all subsequent dimensions.\n",
    "* permute disrupts this pattern without rearranging the underlying data, leading to a non-contiguous tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141cd1c0-7d2b-452b-babc-1248d23eda4c",
   "metadata": {},
   "source": [
    "### Indexing (selecting data from tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "142c03ab-e99b-4270-b6ef-e2424305497e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 2., 3.],\n",
       "          [4., 5., 6.],\n",
       "          [7., 8., 9.]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.arange(1., 10.).reshape(1, 3, 3)\n",
    "tensor, tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4704baa0-1321-4797-b73c-66a6b72b103b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First bracket: tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "Second bracket: tensor([1., 2., 3.])\n",
      "Third bracket: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"First bracket: {tensor[0]}\")\n",
    "print(f\"Second bracket: {tensor[0][0]}\")\n",
    "print(f\"Third bracket: {tensor[0][0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d12d271f-ead3-4773-af26-618a8e2648c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th dimension and the 0 index of 1st dimension\n",
    "tensor[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8c72b557-0a23-4694-864b-3daafcf68c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5., 8.]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th & 1st dimensions but only index 1 of 2nd dimension\n",
    "tensor[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d9a98688-03f3-43a4-906e-03e55cdac1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
    "tensor[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e907efa9-1e28-4afb-a999-31a4f095696e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension \n",
    "tensor[0, 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25b2512-0442-43f8-b584-20415ba1ad8e",
   "metadata": {},
   "source": [
    "### PyTorch tensors & NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "329b5751-c306-466b-b837-1c96716fce3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(1., 8.)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "44ef43e5-adf4-4fd0-8abf-83dae124c11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "df40bf2b-8634-47cc-b352-5c52585384a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4, 5, 6, 7]), tensor([1, 2, 3, 4, 5, 6, 7]))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(1, 8)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ecaf1d54-1a4a-48c9-8401-bd201823e5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('int64'), torch.int64)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.dtype, tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "22628f85-debe-498c-ad1f-c0603bb08231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.ones(7)\n",
    "np_array = tensor.numpy()\n",
    "tensor, np_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f32dcd-3a86-4882-9359-3ae58dc9334e",
   "metadata": {},
   "source": [
    "### Reproducibility (taking random out of random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "cb5c5040-2db6-47e7-b540-6ea6f7bbff1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9147, 0.2036, 0.2018, 0.2018],\n",
      "        [0.9497, 0.6666, 0.9811, 0.0874],\n",
      "        [0.0041, 0.1088, 0.1637, 0.7025]])\n",
      "tensor([[0.6790, 0.9155, 0.2418, 0.1591],\n",
      "        [0.7653, 0.2979, 0.8035, 0.3813],\n",
      "        [0.7860, 0.1115, 0.2477, 0.6524]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "random_tensor_a = torch.rand(3, 4)\n",
    "random_tensor_b = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_a)\n",
    "print(random_tensor_b)\n",
    "print(random_tensor_a == random_tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4ca0fbdc-c8e0-4719-a7ea-2980ed651135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "random_tensor_a = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "random_tensor_b = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_a)\n",
    "print(random_tensor_b)\n",
    "print(random_tensor_a == random_tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "1396f37c-a1e4-46a8-b797-757ae6c9cf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
      "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
      "        [0.2696, 0.4414, 0.2969, 0.8317]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "random_tensor_a = torch.rand(3, 4)\n",
    "\n",
    "random_tensor_b = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_a)\n",
    "print(random_tensor_b)\n",
    "print(random_tensor_a == random_tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "672aac6e-ee09-4444-bc0d-3d2bcc821707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
      "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
      "        [0.2696, 0.4414, 0.2969, 0.8317]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "random_tensor_c = torch.rand(3, 4)\n",
    "random_tensor_d = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_c)\n",
    "print(random_tensor_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "909c025e-9649-4b27-9651-7f56a8d2d015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
      "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
      "        [0.2696, 0.4414, 0.2969, 0.8317]])\n",
      "tensor([[0.1053, 0.2695, 0.3588, 0.1994],\n",
      "        [0.5472, 0.0062, 0.9516, 0.0753],\n",
      "        [0.8860, 0.5832, 0.3376, 0.8090]])\n",
      "tensor([[0.5779, 0.9040, 0.5547, 0.3423],\n",
      "        [0.6343, 0.3644, 0.7104, 0.9464],\n",
      "        [0.7890, 0.2814, 0.7886, 0.5895]])\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "random_tensor_a = torch.rand(3, 4)\n",
    "random_tensor_b = torch.rand(3, 4)\n",
    "random_tensor_c = torch.rand(3, 4)\n",
    "random_tensor_d = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_a)\n",
    "print(random_tensor_b)\n",
    "print(random_tensor_c)\n",
    "print(random_tensor_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b451cb9b-13dd-4122-8d60-5f8502bf2a69",
   "metadata": {},
   "source": [
    "### Running tensors on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e708ae9a-ce41-4223-ae9e-1ad3306e5312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "48311c63-c039-45ff-b626-ba38e302e673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f1795a13-e5ee-4ee4-b365-5b10a97880d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mps.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "3831a2c9-fed9-493f-9167-4b835bf722c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"  # use NVIDIA GPU if available\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"  # use Apple Silicon GPU if available\n",
    "else:\n",
    "    device = \"cpu\"  # defaults to CPU if no GPU is available\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "61cd4026-0062-49ac-ad75-973be5a1237f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([1, 2, 3], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(1, 4)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "\n",
    "print(tensor)\n",
    "print(tensor_on_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "9cb0363a-92f0-4fcc-8193-f76104b017d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tensor_on_cpu = tensor_on_gpu.numpy()\n",
    "except Exception as e:\n",
    "    print(f\"Failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "2439e775-9ba4-4522-8465-6758ea6df913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_on_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16536b5-26f9-419a-89d6-05ed10228788",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "5b5b5db6-49b5-4256-b723-11ac0f214458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7539, 0.1952, 0.0050, 0.3068, 0.1165, 0.9103, 0.6440],\n",
       "        [0.7071, 0.6581, 0.4913, 0.8913, 0.1447, 0.5315, 0.1587],\n",
       "        [0.6542, 0.3278, 0.6532, 0.3958, 0.9147, 0.2036, 0.2018],\n",
       "        [0.2018, 0.9497, 0.6666, 0.9811, 0.0874, 0.0041, 0.1088],\n",
       "        [0.1637, 0.7025, 0.6790, 0.9155, 0.2418, 0.1591, 0.7653],\n",
       "        [0.2979, 0.8035, 0.3813, 0.7860, 0.1115, 0.2477, 0.6524],\n",
       "        [0.6057, 0.3725, 0.7980, 0.8399, 0.1374, 0.2331, 0.9578]])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random tensor with shape (7, 7).\n",
    "tensor = torch.rand(7, 7)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "e1e32be3-a707-4454-a55b-6e554db2366c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6545],\n",
       "        [1.0373],\n",
       "        [1.1938],\n",
       "        [0.9486],\n",
       "        [1.0736],\n",
       "        [0.8781],\n",
       "        [1.1626]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform a matrix multiplication on the tensor from 2 with another random tensor with shape (1, 7)\n",
    "tensor_2 = torch.rand(1, 7)\n",
    "\n",
    "tensor_3 = tensor @ tensor_2.T\n",
    "tensor_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "3cbb9b18-f429-49b4-9c54-770f57d7b683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8542],\n",
       "        [1.9611],\n",
       "        [2.2884],\n",
       "        [3.0481],\n",
       "        [1.7067],\n",
       "        [2.5290],\n",
       "        [1.7989]])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed to 0 and do 2 & 3 over again.\n",
    "# The output should be:\n",
    "\n",
    "# (tensor([[1.8542],\n",
    "#          [1.9611],\n",
    "#          [2.2884],\n",
    "#          [3.0481],\n",
    "#          [1.7067],\n",
    "#          [2.5290],\n",
    "#          [1.7989]]), torch.Size([7, 1]))\n",
    "\n",
    "RANDOM_SEED = 0 \n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "tensor_a = torch.rand(7, 7)\n",
    "tensor_b = torch.rand(1, 7)\n",
    "tensor_c = tensor_a @ tensor_b.T\n",
    "tensor_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "df605d5e-aaf2-4d59-886c-5f59f367ffc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0290, 0.4019, 0.2598],\n",
      "        [0.3666, 0.0583, 0.7006]], device='mps:0')\n",
      "tensor([[0.0518, 0.4681, 0.6738],\n",
      "        [0.3315, 0.7837, 0.5631]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Create two random tensors of shape (2, 3) and send them both to the GPU (you'll need access to a GPU for this). Set torch.manual_seed(1234) when creating the tensors (this doesn't have to be the GPU random seed). The output should be something like:\n",
    "# Device: cuda\n",
    "# (tensor([[0.0290, 0.4019, 0.2598],\n",
    "#          [0.3666, 0.0583, 0.7006]], device='cuda:0'),\n",
    "#  tensor([[0.0518, 0.4681, 0.6738],\n",
    "#          [0.3315, 0.7837, 0.5631]], device='cuda:0'))\n",
    "\n",
    "RANDOM_SEED = 1234\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "\n",
    "tensor_a = torch.rand(2, 3).to(device)\n",
    "tensor_b = torch.rand(2, 3).to(device)\n",
    "\n",
    "print(tensor_a)\n",
    "print(tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "605ad988-db7f-4c6f-840b-24e07c7dd7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3647, 0.4709],\n",
       "        [0.5184, 0.5617]], device='mps:0')"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Perform a matrix multiplication on the tensors you created in 6\n",
    "tensor_c = tensor_a @ tensor_b.T\n",
    "tensor_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "087115b6-8b3a-4e49-8a94-ee559cdbcefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5617, device='mps:0')\n",
      "tensor(0.3647, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Find the maximum and minimum values of the output of 7\n",
    "print(torch.max(tensor_c))\n",
    "print(torch.min(tensor_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "0487ae1b-ed2a-40bf-b2df-ec6078e73b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3, device='mps:0')\n",
      "tensor(0, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Find the maximum and minimum index values of the output of 7\n",
    "print(torch.argmax(tensor_c))\n",
    "print(torch.argmin(tensor_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "57d9b5ba-6f31-4380-a475-a4adac5fdc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
      "           0.3653, 0.8513]]]])\n",
      "torch.Size([1, 1, 1, 10])\n",
      "tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
      "        0.8513])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "#  Make a random tensor with shape (1, 1, 1, 10) and then create a new tensor with all the 1 dimensions removed to be left with a tensor of shape (10). \n",
    "# Set the seed to 7 when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape.\n",
    "# The output should look like:\n",
    "\n",
    "# tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
    "#            0.3653, 0.8513]]]]) torch.Size([1, 1, 1, 10])\n",
    "# \n",
    "# tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
    "#         0.8513]) torch.Size([10])\n",
    "\n",
    "RANDOM_SEED = 7\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "tensor_a = torch.rand(1, 1, 1, 10)\n",
    "tensor_b = tensor_a.squeeze()\n",
    "\n",
    "print(tensor_a)\n",
    "print(tensor_a.shape)\n",
    "print(tensor_b)\n",
    "print(tensor_b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4068d12-eca3-4814-b341-95cf9fc7fb25",
   "metadata": {},
   "source": [
    "### Fashion MNIST model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "fef90d54-7a5a-4945-b691-8804edd0700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "9b653717-e051-46a7-aa65-f27854810b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading train and test dataset from open vision datasets\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "ccc80f09-f1a9-4d70-bfd7-9a80b37f7888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28]) torch.float32\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in train_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape} {X.dtype}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "b8dad533-d2b3-4ff3-875c-78d87de1c2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "722f9091-b4c4-41e1-b400-93a22e319bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "aebeadc1-5ffa-4850-addf-00edd6e337f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "87ff72a6-bcf0-494a-a28a-65799b68fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "979652f5-3341-4669-b97e-0aba5a6bd9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.306602  [   64/60000]\n",
      "loss: 2.290009  [ 6464/60000]\n",
      "loss: 2.269770  [12864/60000]\n",
      "loss: 2.260979  [19264/60000]\n",
      "loss: 2.251373  [25664/60000]\n",
      "loss: 2.214774  [32064/60000]\n",
      "loss: 2.232035  [38464/60000]\n",
      "loss: 2.188872  [44864/60000]\n",
      "loss: 2.188063  [51264/60000]\n",
      "loss: 2.153989  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 40.6%, Avg loss: 2.150521 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.161589  [   64/60000]\n",
      "loss: 2.152027  [ 6464/60000]\n",
      "loss: 2.087591  [12864/60000]\n",
      "loss: 2.107097  [19264/60000]\n",
      "loss: 2.057354  [25664/60000]\n",
      "loss: 1.984516  [32064/60000]\n",
      "loss: 2.027601  [38464/60000]\n",
      "loss: 1.933577  [44864/60000]\n",
      "loss: 1.946321  [51264/60000]\n",
      "loss: 1.870152  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 1.870605 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.898082  [   64/60000]\n",
      "loss: 1.873238  [ 6464/60000]\n",
      "loss: 1.747605  [12864/60000]\n",
      "loss: 1.802230  [19264/60000]\n",
      "loss: 1.680043  [25664/60000]\n",
      "loss: 1.627109  [32064/60000]\n",
      "loss: 1.662467  [38464/60000]\n",
      "loss: 1.550388  [44864/60000]\n",
      "loss: 1.583026  [51264/60000]\n",
      "loss: 1.472656  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.6%, Avg loss: 1.497829 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.558501  [   64/60000]\n",
      "loss: 1.532433  [ 6464/60000]\n",
      "loss: 1.378683  [12864/60000]\n",
      "loss: 1.460050  [19264/60000]\n",
      "loss: 1.331739  [25664/60000]\n",
      "loss: 1.329180  [32064/60000]\n",
      "loss: 1.348215  [38464/60000]\n",
      "loss: 1.265169  [44864/60000]\n",
      "loss: 1.305001  [51264/60000]\n",
      "loss: 1.199229  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.235437 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.307925  [   64/60000]\n",
      "loss: 1.296891  [ 6464/60000]\n",
      "loss: 1.129410  [12864/60000]\n",
      "loss: 1.241311  [19264/60000]\n",
      "loss: 1.115342  [25664/60000]\n",
      "loss: 1.138135  [32064/60000]\n",
      "loss: 1.163642  [38464/60000]\n",
      "loss: 1.091883  [44864/60000]\n",
      "loss: 1.134799  [51264/60000]\n",
      "loss: 1.046317  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 1.076542 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "a6af819d-1008-4d46-891f-d86e3d51cc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "f6010221-c454-426a-9c78-64fb1a2ee06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zk/thhxnpgj5xd1lq4z__k6cswr0000gp/T/ipykernel_40961/2085806346.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "aba75490-a492-4082-bd83-fbe51f308798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e76f02-930d-4fc1-9fbb-f49648061147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
